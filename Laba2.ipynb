{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkConf, SparkContext, SparkSession\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n",
        "\n",
        "# Загрузка стоп-слов и инициализация стеммера\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "# Настройка Spark\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local[*]\")\\\n",
        "        .appName(\"TextAnalyzer\")\\\n",
        "        .getOrCreate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgRbD8kbH9au",
        "outputId": "a9b5efe5-e401-432a-f91d-59bfb2cf5750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext\n",
        "# Загрузка текста\n",
        "text_file = sc.textFile(\"/content/drive/MyDrive/Colab Notebooks/pg1399.txt\")\n",
        "\n",
        "# 1. Очистка текста\n",
        "def clean_text(line):\n",
        "    line = re.sub(r'[^\\w\\s]', '', line)\n",
        "    words = line.lower().split()\n",
        "    return [word for word in words if word not in stop_words]\n",
        "\n",
        "cleaned_rdd = text_file.flatMap(clean_text)\n",
        "\n",
        "# 2. Лямбда-функция для подсчета количества слов\n",
        "word_counts = cleaned_rdd.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
        "# Получение и сортировка по частоте\n",
        "sorted_word_counts = word_counts.collect()\n",
        "sorted_word_counts.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# 3. Вывод тoп 50 наиболее распространенных слов\n",
        "print(\"Top 50 most common words:\")\n",
        "for word, count in sorted_word_counts[:50]:\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "# 3. Вывод тoп 50 наименее распространенных слов\n",
        "print(\"\\nTop 50 least common words:\")\n",
        "for word, count in sorted_word_counts[-50:]:\n",
        "    print(f\"{word}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYt-yfNJK4-P",
        "outputId": "007b2460-fd2b-4677-a1fd-91e2af2608f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 50 most common words:\n",
            "said: 2725\n",
            "levin: 1512\n",
            "one: 1157\n",
            "would: 1044\n",
            "could: 971\n",
            "vronsky: 769\n",
            "anna: 739\n",
            "go: 682\n",
            "well: 676\n",
            "know: 671\n",
            "come: 667\n",
            "went: 661\n",
            "alexey: 627\n",
            "see: 612\n",
            "kitty: 596\n",
            "time: 564\n",
            "thought: 563\n",
            "felt: 553\n",
            "dont: 550\n",
            "stepan: 548\n",
            "eyes: 547\n",
            "face: 539\n",
            "yes: 536\n",
            "nothing: 530\n",
            "alexandrovitch: 524\n",
            "man: 522\n",
            "though: 521\n",
            "like: 516\n",
            "say: 513\n",
            "arkadyevitch: 510\n",
            "little: 460\n",
            "life: 451\n",
            "without: 429\n",
            "something: 427\n",
            "away: 427\n",
            "im: 425\n",
            "love: 425\n",
            "must: 425\n",
            "still: 425\n",
            "came: 421\n",
            "saw: 421\n",
            "going: 408\n",
            "never: 407\n",
            "made: 402\n",
            "old: 394\n",
            "knew: 390\n",
            "hand: 385\n",
            "long: 369\n",
            "began: 365\n",
            "wife: 364\n",
            "\n",
            "Top 50 least common words:\n",
            "processing: 1\n",
            "hypertext: 1\n",
            "exporting: 1\n",
            "periodic: 1\n",
            "notifies: 1\n",
            "discontinue: 1\n",
            "1f1: 1\n",
            "employees: 1\n",
            "infringement: 1\n",
            "damaged: 1\n",
            "virus: 1\n",
            "codes: 1\n",
            "disclaim: 1\n",
            "distributor: 1\n",
            "1f4: 1\n",
            "merchantability: 1\n",
            "fitness: 1\n",
            "exclusion: 1\n",
            "maximum: 1\n",
            "invalidity: 1\n",
            "void: 1\n",
            "indemnity: 1\n",
            "employee: 1\n",
            "readable: 1\n",
            "gutenbergtms: 1\n",
            "goals: 1\n",
            "ensuring: 1\n",
            "2001: 1\n",
            "identification: 1\n",
            "deductible: 1\n",
            "809: 1\n",
            "north: 1\n",
            "1500: 1\n",
            "ut: 1\n",
            "84116: 1\n",
            "survive: 1\n",
            "licensed: 1\n",
            "outdated: 1\n",
            "5000: 1\n",
            "irs: 1\n",
            "paperwork: 1\n",
            "solicitation: 1\n",
            "unsolicited: 1\n",
            "international: 1\n",
            "web: 1\n",
            "donation: 1\n",
            "originator: 1\n",
            "pg: 1\n",
            "includes: 1\n",
            "newsletter: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для стемминга слов\n",
        "def stem_word(word):\n",
        "    return stemmer.stem(word)\n",
        "\n",
        "# 4.Стемминг слов\n",
        "stemmed_rdd = cleaned_rdd.map(stem_word)\n",
        "# Повторный подсчет слов после стемминга\n",
        "stemmed_word_counts = stemmed_rdd.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "# Сортировка\n",
        "sorted_stemmed_word_counts = stemmed_word_counts.collect()\n",
        "sorted_stemmed_word_counts.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# 5. Вывод топ 50 наиболее распространенных слов после стемминга\n",
        "print(\"\\nTop 50 most common stemmed words:\")\n",
        "for word, count in sorted_stemmed_word_counts[:50]:\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "# 5. Вывод топ 50 наименее распространенных слов после стемминга\n",
        "print(\"\\nTop 50 least common stemmed words:\")\n",
        "for word, count in sorted_stemmed_word_counts[-50:]:\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "# Остановка контекста Spark\n",
        "sc.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yyn76l1YTuoR",
        "outputId": "7db54c39-7526-40c4-b276-60b0ae0d4af7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 50 most common stemmed words:\n",
            "said: 2725\n",
            "levin: 1624\n",
            "one: 1239\n",
            "go: 1090\n",
            "would: 1044\n",
            "look: 999\n",
            "could: 971\n",
            "come: 887\n",
            "vronski: 857\n",
            "anna: 821\n",
            "know: 809\n",
            "see: 783\n",
            "say: 714\n",
            "like: 696\n",
            "well: 678\n",
            "kitti: 670\n",
            "went: 661\n",
            "thought: 658\n",
            "time: 650\n",
            "hand: 645\n",
            "smile: 631\n",
            "alexey: 630\n",
            "face: 588\n",
            "love: 586\n",
            "alexandrovitch: 571\n",
            "eye: 567\n",
            "feel: 557\n",
            "man: 556\n",
            "felt: 553\n",
            "dont: 550\n",
            "stepan: 548\n",
            "arkadyevitch: 547\n",
            "ye: 536\n",
            "noth: 532\n",
            "though: 521\n",
            "ask: 491\n",
            "think: 488\n",
            "get: 485\n",
            "even: 481\n",
            "talk: 481\n",
            "littl: 460\n",
            "life: 453\n",
            "want: 453\n",
            "answer: 432\n",
            "still: 431\n",
            "long: 429\n",
            "without: 429\n",
            "someth: 427\n",
            "away: 427\n",
            "day: 427\n",
            "\n",
            "Top 50 least common stemmed words:\n",
            "buddhist: 1\n",
            "whichi: 1\n",
            "buddhistswhat: 1\n",
            "birchtre: 1\n",
            "meridian: 1\n",
            "starlight: 1\n",
            "tactlessli: 1\n",
            "renam: 1\n",
            "trademarkcopyright: 1\n",
            "1d: 1\n",
            "download: 1\n",
            "reus: 1\n",
            "1e2: 1\n",
            "unlink: 1\n",
            "detach: 1\n",
            "1e5: 1\n",
            "1e6: 1\n",
            "binari: 1\n",
            "nonproprietari: 1\n",
            "proprietari: 1\n",
            "hypertext: 1\n",
            "discontinu: 1\n",
            "1f1: 1\n",
            "identifi: 1\n",
            "inaccur: 1\n",
            "transcript: 1\n",
            "infring: 1\n",
            "1f4: 1\n",
            "violat: 1\n",
            "maximum: 1\n",
            "unenforc: 1\n",
            "void: 1\n",
            "indemn: 1\n",
            "modif: 1\n",
            "readabl: 1\n",
            "2001: 1\n",
            "identif: 1\n",
            "809: 1\n",
            "north: 1\n",
            "1500: 1\n",
            "ut: 1\n",
            "84116: 1\n",
            "machineread: 1\n",
            "5000: 1\n",
            "paperwork: 1\n",
            "unsolicit: 1\n",
            "donor: 1\n",
            "web: 1\n",
            "pg: 1\n",
            "newslett: 1\n"
          ]
        }
      ]
    }
  ]
}